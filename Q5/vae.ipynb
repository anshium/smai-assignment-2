{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Auto-Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root=\"./mnist_data/\", train = True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root=\"./mnist_data/\", train = False, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle = True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim_1, h_dim_2, z_dim):\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "\n",
    "        self.x_dim = x_dim\n",
    "        self.h_dim_1 = h_dim_1\n",
    "        self.h_dim_2 = h_dim_2\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim_1)\n",
    "        self.fc2 = nn.Linear(h_dim_1, h_dim_2)\n",
    "        self.fc31 = nn.Linear(h_dim_2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim_2, z_dim)\n",
    "\n",
    "\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim_2)\n",
    "        self.fc5 = nn.Linear(h_dim_2, h_dim_1)\n",
    "        self.fc6 = nn.Linear(h_dim_1, x_dim)\n",
    "\n",
    "    def encoder(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "\n",
    "        return self.fc31(h), self.fc32(h)\n",
    "\n",
    "    '''\n",
    "    1. What is log_var.\n",
    "    2. What is mu.\n",
    "\n",
    "    Are they part of that parameterisation trick they were mentioning about?\n",
    "\n",
    "    I think I get this now, somewhat.\n",
    "    '''\n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "\n",
    "        return eps.mul(std).add(mu)\n",
    "\n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc4(z)) # Why not 2x here\n",
    "        h = F.relu(self.fc5(h))\n",
    "\n",
    "        return F.sigmoid(self.fc6(h))\n",
    "\n",
    "\n",
    "    '''\n",
    "    When we would do a backward pass, why wouldn't z be learnt - like mu and log_var\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, 784))\n",
    "\n",
    "        z = self.sampling(mu, log_var)\n",
    "\n",
    "        return self.decoder(z), mu, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model, Optimiser and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VariationalAutoEncoder(x_dim = 28 * 28, h_dim_1 = 512, h_dim_2 = 256, z_dim = 2)\n",
    "\n",
    "# Is there any other way of setting the device?\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()\n",
    "\n",
    "optimiser = optim.Adam(vae.parameters())\n",
    "\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    x = x.view(x.size(0), -1)  # Flatten target to match recon_x shape\n",
    "\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction=\"sum\")\n",
    "\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vae.train()\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.cuda()\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        recon_batch, mu, log_var = vae(data)\n",
    "\n",
    "        loss = loss_function(recon_batch, data, mu, log_var)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        train_loss += loss.item() # .item() returns the value of the tensor as a standard python number\n",
    "\n",
    "        optimiser.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    vae.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            data = data.cuda()\n",
    "\n",
    "            recon, mu, log_var = vae(data)\n",
    "\n",
    "            # summing up the batch loss\n",
    "            test_loss += loss_function(recon, data, mu, log_var).item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset) # Average\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 544.966172\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 188.750176\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 173.291309\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 168.363770\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 168.133945\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 159.189766\n",
      "====> Epoch: 1 Average loss: 178.4591\n",
      "====> Test set loss: 162.8736\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 163.304434\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 162.468467\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 157.115332\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 164.491582\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 157.383037\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 161.157451\n",
      "====> Epoch: 2 Average loss: 158.0970\n",
      "====> Test set loss: 155.3253\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 161.630283\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 144.600869\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 151.611514\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 156.518203\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 153.388955\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 152.853330\n",
      "====> Epoch: 3 Average loss: 152.6814\n",
      "====> Test set loss: 151.3017\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 151.254053\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 149.739043\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 143.187256\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 155.864385\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 142.564209\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 142.844775\n",
      "====> Epoch: 4 Average loss: 149.4315\n",
      "====> Test set loss: 148.9919\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 147.312109\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 144.888770\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 141.692842\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 140.614092\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 145.179512\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 154.430391\n",
      "====> Epoch: 5 Average loss: 147.5280\n",
      "====> Test set loss: 147.3617\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 148.431143\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 146.430908\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 146.796768\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 140.573750\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 151.903525\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 147.868555\n",
      "====> Epoch: 6 Average loss: 146.0237\n",
      "====> Test set loss: 145.4797\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 156.877031\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 151.066846\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 155.172334\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 145.448145\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 146.895430\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 144.425635\n",
      "====> Epoch: 7 Average loss: 144.9253\n",
      "====> Test set loss: 145.2165\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 148.292588\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 143.077881\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 137.847158\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 151.033770\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 153.250654\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 155.557988\n",
      "====> Epoch: 8 Average loss: 144.0395\n",
      "====> Test set loss: 144.3190\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 145.953066\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 144.623613\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 145.287705\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 146.986582\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 135.950820\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 144.245732\n",
      "====> Epoch: 9 Average loss: 143.3779\n",
      "====> Test set loss: 144.6000\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 147.140186\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 144.068613\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 138.504775\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 134.750127\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 138.508965\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 141.784209\n",
      "====> Epoch: 10 Average loss: 142.7153\n",
      "====> Test set loss: 143.3166\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 144.892881\n",
      "Train Epoch: 11 [10000/60000 (17%)]\tLoss: 131.495928\n",
      "Train Epoch: 11 [20000/60000 (33%)]\tLoss: 149.080742\n",
      "Train Epoch: 11 [30000/60000 (50%)]\tLoss: 135.286670\n",
      "Train Epoch: 11 [40000/60000 (67%)]\tLoss: 138.773604\n",
      "Train Epoch: 11 [50000/60000 (83%)]\tLoss: 141.179121\n",
      "====> Epoch: 11 Average loss: 142.2038\n",
      "====> Test set loss: 143.1936\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 142.095205\n",
      "Train Epoch: 12 [10000/60000 (17%)]\tLoss: 142.441670\n",
      "Train Epoch: 12 [20000/60000 (33%)]\tLoss: 136.809336\n",
      "Train Epoch: 12 [30000/60000 (50%)]\tLoss: 142.019346\n",
      "Train Epoch: 12 [40000/60000 (67%)]\tLoss: 143.328750\n",
      "Train Epoch: 12 [50000/60000 (83%)]\tLoss: 142.083984\n",
      "====> Epoch: 12 Average loss: 141.7516\n",
      "====> Test set loss: 143.0128\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 149.952471\n",
      "Train Epoch: 13 [10000/60000 (17%)]\tLoss: 140.874687\n",
      "Train Epoch: 13 [20000/60000 (33%)]\tLoss: 136.273535\n",
      "Train Epoch: 13 [30000/60000 (50%)]\tLoss: 139.270654\n",
      "Train Epoch: 13 [40000/60000 (67%)]\tLoss: 144.949668\n",
      "Train Epoch: 13 [50000/60000 (83%)]\tLoss: 145.503955\n",
      "====> Epoch: 13 Average loss: 141.3686\n",
      "====> Test set loss: 142.7871\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 143.933203\n",
      "Train Epoch: 14 [10000/60000 (17%)]\tLoss: 145.475928\n",
      "Train Epoch: 14 [20000/60000 (33%)]\tLoss: 137.281924\n",
      "Train Epoch: 14 [30000/60000 (50%)]\tLoss: 142.152939\n",
      "Train Epoch: 14 [40000/60000 (67%)]\tLoss: 136.129912\n",
      "Train Epoch: 14 [50000/60000 (83%)]\tLoss: 137.453564\n",
      "====> Epoch: 14 Average loss: 141.0278\n",
      "====> Test set loss: 141.8062\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 141.933545\n",
      "Train Epoch: 15 [10000/60000 (17%)]\tLoss: 136.221455\n",
      "Train Epoch: 15 [20000/60000 (33%)]\tLoss: 136.040996\n",
      "Train Epoch: 15 [30000/60000 (50%)]\tLoss: 142.623740\n",
      "Train Epoch: 15 [40000/60000 (67%)]\tLoss: 142.477480\n",
      "Train Epoch: 15 [50000/60000 (83%)]\tLoss: 136.552012\n",
      "====> Epoch: 15 Average loss: 140.6396\n",
      "====> Test set loss: 142.2898\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 133.316426\n",
      "Train Epoch: 16 [10000/60000 (17%)]\tLoss: 146.363848\n",
      "Train Epoch: 16 [20000/60000 (33%)]\tLoss: 133.107285\n",
      "Train Epoch: 16 [30000/60000 (50%)]\tLoss: 135.433574\n",
      "Train Epoch: 16 [40000/60000 (67%)]\tLoss: 137.236387\n",
      "Train Epoch: 16 [50000/60000 (83%)]\tLoss: 151.021260\n",
      "====> Epoch: 16 Average loss: 140.4575\n",
      "====> Test set loss: 141.7400\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 141.737148\n",
      "Train Epoch: 17 [10000/60000 (17%)]\tLoss: 131.472979\n",
      "Train Epoch: 17 [20000/60000 (33%)]\tLoss: 132.480352\n",
      "Train Epoch: 17 [30000/60000 (50%)]\tLoss: 144.098916\n",
      "Train Epoch: 17 [40000/60000 (67%)]\tLoss: 140.602783\n",
      "Train Epoch: 17 [50000/60000 (83%)]\tLoss: 142.793760\n",
      "====> Epoch: 17 Average loss: 140.0839\n",
      "====> Test set loss: 141.5273\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 138.353428\n",
      "Train Epoch: 18 [10000/60000 (17%)]\tLoss: 141.573584\n",
      "Train Epoch: 18 [20000/60000 (33%)]\tLoss: 134.359990\n",
      "Train Epoch: 18 [30000/60000 (50%)]\tLoss: 147.807832\n",
      "Train Epoch: 18 [40000/60000 (67%)]\tLoss: 138.276230\n",
      "Train Epoch: 18 [50000/60000 (83%)]\tLoss: 141.804150\n",
      "====> Epoch: 18 Average loss: 139.8136\n",
      "====> Test set loss: 141.0965\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 147.039004\n",
      "Train Epoch: 19 [10000/60000 (17%)]\tLoss: 134.356875\n",
      "Train Epoch: 19 [20000/60000 (33%)]\tLoss: 140.738770\n",
      "Train Epoch: 19 [30000/60000 (50%)]\tLoss: 142.999141\n",
      "Train Epoch: 19 [40000/60000 (67%)]\tLoss: 136.277402\n",
      "Train Epoch: 19 [50000/60000 (83%)]\tLoss: 140.817939\n",
      "====> Epoch: 19 Average loss: 139.8567\n",
      "====> Test set loss: 141.2006\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 139.280352\n",
      "Train Epoch: 20 [10000/60000 (17%)]\tLoss: 145.197773\n",
      "Train Epoch: 20 [20000/60000 (33%)]\tLoss: 145.770752\n",
      "Train Epoch: 20 [30000/60000 (50%)]\tLoss: 137.516875\n",
      "Train Epoch: 20 [40000/60000 (67%)]\tLoss: 143.183945\n",
      "Train Epoch: 20 [50000/60000 (83%)]\tLoss: 145.299053\n",
      "====> Epoch: 20 Average loss: 139.7382\n",
      "====> Test set loss: 140.6608\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 139.655918\n",
      "Train Epoch: 21 [10000/60000 (17%)]\tLoss: 134.821152\n",
      "Train Epoch: 21 [20000/60000 (33%)]\tLoss: 137.837744\n",
      "Train Epoch: 21 [30000/60000 (50%)]\tLoss: 137.462910\n",
      "Train Epoch: 21 [40000/60000 (67%)]\tLoss: 138.845840\n",
      "Train Epoch: 21 [50000/60000 (83%)]\tLoss: 147.356943\n",
      "====> Epoch: 21 Average loss: 139.2090\n",
      "====> Test set loss: 140.4547\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 138.767529\n",
      "Train Epoch: 22 [10000/60000 (17%)]\tLoss: 136.713154\n",
      "Train Epoch: 22 [20000/60000 (33%)]\tLoss: 139.673613\n",
      "Train Epoch: 22 [30000/60000 (50%)]\tLoss: 140.713984\n",
      "Train Epoch: 22 [40000/60000 (67%)]\tLoss: 137.474561\n",
      "Train Epoch: 22 [50000/60000 (83%)]\tLoss: 141.859971\n",
      "====> Epoch: 22 Average loss: 138.8783\n",
      "====> Test set loss: 140.6876\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 137.395537\n",
      "Train Epoch: 23 [10000/60000 (17%)]\tLoss: 135.718516\n",
      "Train Epoch: 23 [20000/60000 (33%)]\tLoss: 142.186504\n",
      "Train Epoch: 23 [30000/60000 (50%)]\tLoss: 142.279043\n",
      "Train Epoch: 23 [40000/60000 (67%)]\tLoss: 142.539336\n",
      "Train Epoch: 23 [50000/60000 (83%)]\tLoss: 140.144268\n",
      "====> Epoch: 23 Average loss: 138.6349\n",
      "====> Test set loss: 140.1391\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 149.504326\n",
      "Train Epoch: 24 [10000/60000 (17%)]\tLoss: 141.382598\n",
      "Train Epoch: 24 [20000/60000 (33%)]\tLoss: 137.798965\n",
      "Train Epoch: 24 [30000/60000 (50%)]\tLoss: 138.487197\n",
      "Train Epoch: 24 [40000/60000 (67%)]\tLoss: 135.622344\n",
      "Train Epoch: 24 [50000/60000 (83%)]\tLoss: 141.550840\n",
      "====> Epoch: 24 Average loss: 138.2915\n",
      "====> Test set loss: 139.9076\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 133.425938\n",
      "Train Epoch: 25 [10000/60000 (17%)]\tLoss: 129.171670\n",
      "Train Epoch: 25 [20000/60000 (33%)]\tLoss: 139.113047\n",
      "Train Epoch: 25 [30000/60000 (50%)]\tLoss: 137.618477\n",
      "Train Epoch: 25 [40000/60000 (67%)]\tLoss: 137.469521\n",
      "Train Epoch: 25 [50000/60000 (83%)]\tLoss: 137.214971\n",
      "====> Epoch: 25 Average loss: 138.3830\n",
      "====> Test set loss: 139.7654\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 134.408564\n",
      "Train Epoch: 26 [10000/60000 (17%)]\tLoss: 132.166680\n",
      "Train Epoch: 26 [20000/60000 (33%)]\tLoss: 139.566426\n",
      "Train Epoch: 26 [30000/60000 (50%)]\tLoss: 128.465332\n",
      "Train Epoch: 26 [40000/60000 (67%)]\tLoss: 135.529219\n",
      "Train Epoch: 26 [50000/60000 (83%)]\tLoss: 136.585137\n",
      "====> Epoch: 26 Average loss: 138.0831\n",
      "====> Test set loss: 140.5536\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 139.330322\n",
      "Train Epoch: 27 [10000/60000 (17%)]\tLoss: 135.583975\n",
      "Train Epoch: 27 [20000/60000 (33%)]\tLoss: 133.863447\n",
      "Train Epoch: 27 [30000/60000 (50%)]\tLoss: 149.270684\n",
      "Train Epoch: 27 [40000/60000 (67%)]\tLoss: 137.570352\n",
      "Train Epoch: 27 [50000/60000 (83%)]\tLoss: 138.568545\n",
      "====> Epoch: 27 Average loss: 137.8748\n",
      "====> Test set loss: 139.8358\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 129.627471\n",
      "Train Epoch: 28 [10000/60000 (17%)]\tLoss: 139.071465\n",
      "Train Epoch: 28 [20000/60000 (33%)]\tLoss: 137.621035\n",
      "Train Epoch: 28 [30000/60000 (50%)]\tLoss: 127.532559\n",
      "Train Epoch: 28 [40000/60000 (67%)]\tLoss: 135.817080\n",
      "Train Epoch: 28 [50000/60000 (83%)]\tLoss: 140.821074\n",
      "====> Epoch: 28 Average loss: 137.6025\n",
      "====> Test set loss: 139.2420\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 140.976611\n",
      "Train Epoch: 29 [10000/60000 (17%)]\tLoss: 134.302188\n",
      "Train Epoch: 29 [20000/60000 (33%)]\tLoss: 133.100811\n",
      "Train Epoch: 29 [30000/60000 (50%)]\tLoss: 130.397305\n",
      "Train Epoch: 29 [40000/60000 (67%)]\tLoss: 132.671729\n",
      "Train Epoch: 29 [50000/60000 (83%)]\tLoss: 138.582842\n",
      "====> Epoch: 29 Average loss: 137.6318\n",
      "====> Test set loss: 140.0508\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 130.722813\n",
      "Train Epoch: 30 [10000/60000 (17%)]\tLoss: 147.373330\n",
      "Train Epoch: 30 [20000/60000 (33%)]\tLoss: 147.745313\n",
      "Train Epoch: 30 [30000/60000 (50%)]\tLoss: 137.820488\n",
      "Train Epoch: 30 [40000/60000 (67%)]\tLoss: 141.874453\n",
      "Train Epoch: 30 [50000/60000 (83%)]\tLoss: 138.931992\n",
      "====> Epoch: 30 Average loss: 137.5637\n",
      "====> Test set loss: 139.5555\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 141.169492\n",
      "Train Epoch: 31 [10000/60000 (17%)]\tLoss: 140.608652\n",
      "Train Epoch: 31 [20000/60000 (33%)]\tLoss: 142.406621\n",
      "Train Epoch: 31 [30000/60000 (50%)]\tLoss: 135.127813\n",
      "Train Epoch: 31 [40000/60000 (67%)]\tLoss: 130.288867\n",
      "Train Epoch: 31 [50000/60000 (83%)]\tLoss: 139.173105\n",
      "====> Epoch: 31 Average loss: 137.1684\n",
      "====> Test set loss: 139.1214\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 139.971396\n",
      "Train Epoch: 32 [10000/60000 (17%)]\tLoss: 135.234746\n",
      "Train Epoch: 32 [20000/60000 (33%)]\tLoss: 132.247588\n",
      "Train Epoch: 32 [30000/60000 (50%)]\tLoss: 124.072471\n",
      "Train Epoch: 32 [40000/60000 (67%)]\tLoss: 133.836338\n",
      "Train Epoch: 32 [50000/60000 (83%)]\tLoss: 133.618135\n",
      "====> Epoch: 32 Average loss: 136.9567\n",
      "====> Test set loss: 138.9167\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 137.133115\n",
      "Train Epoch: 33 [10000/60000 (17%)]\tLoss: 131.205059\n",
      "Train Epoch: 33 [20000/60000 (33%)]\tLoss: 138.640771\n",
      "Train Epoch: 33 [30000/60000 (50%)]\tLoss: 132.369346\n",
      "Train Epoch: 33 [40000/60000 (67%)]\tLoss: 130.242354\n",
      "Train Epoch: 33 [50000/60000 (83%)]\tLoss: 140.233008\n",
      "====> Epoch: 33 Average loss: 137.2328\n",
      "====> Test set loss: 139.1501\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 131.022822\n",
      "Train Epoch: 34 [10000/60000 (17%)]\tLoss: 142.146846\n",
      "Train Epoch: 34 [20000/60000 (33%)]\tLoss: 141.635986\n",
      "Train Epoch: 34 [30000/60000 (50%)]\tLoss: 134.532676\n",
      "Train Epoch: 34 [40000/60000 (67%)]\tLoss: 132.530000\n",
      "Train Epoch: 34 [50000/60000 (83%)]\tLoss: 141.015889\n",
      "====> Epoch: 34 Average loss: 137.1376\n",
      "====> Test set loss: 139.2324\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 134.337334\n",
      "Train Epoch: 35 [10000/60000 (17%)]\tLoss: 129.419717\n",
      "Train Epoch: 35 [20000/60000 (33%)]\tLoss: 133.780313\n",
      "Train Epoch: 35 [30000/60000 (50%)]\tLoss: 132.101680\n",
      "Train Epoch: 35 [40000/60000 (67%)]\tLoss: 132.138242\n",
      "Train Epoch: 35 [50000/60000 (83%)]\tLoss: 131.000234\n",
      "====> Epoch: 35 Average loss: 136.9221\n",
      "====> Test set loss: 138.7195\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 133.189434\n",
      "Train Epoch: 36 [10000/60000 (17%)]\tLoss: 141.949141\n",
      "Train Epoch: 36 [20000/60000 (33%)]\tLoss: 133.906104\n",
      "Train Epoch: 36 [30000/60000 (50%)]\tLoss: 144.056201\n",
      "Train Epoch: 36 [40000/60000 (67%)]\tLoss: 130.447354\n",
      "Train Epoch: 36 [50000/60000 (83%)]\tLoss: 136.784658\n",
      "====> Epoch: 36 Average loss: 136.9850\n",
      "====> Test set loss: 139.1092\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 137.792148\n",
      "Train Epoch: 37 [10000/60000 (17%)]\tLoss: 130.925693\n",
      "Train Epoch: 37 [20000/60000 (33%)]\tLoss: 134.450254\n",
      "Train Epoch: 37 [30000/60000 (50%)]\tLoss: 135.436387\n",
      "Train Epoch: 37 [40000/60000 (67%)]\tLoss: 142.733652\n",
      "Train Epoch: 37 [50000/60000 (83%)]\tLoss: 143.766885\n",
      "====> Epoch: 37 Average loss: 136.5231\n",
      "====> Test set loss: 138.7412\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 140.545195\n",
      "Train Epoch: 38 [10000/60000 (17%)]\tLoss: 136.098945\n",
      "Train Epoch: 38 [20000/60000 (33%)]\tLoss: 143.220127\n",
      "Train Epoch: 38 [30000/60000 (50%)]\tLoss: 133.842246\n",
      "Train Epoch: 38 [40000/60000 (67%)]\tLoss: 145.013193\n",
      "Train Epoch: 38 [50000/60000 (83%)]\tLoss: 136.771357\n",
      "====> Epoch: 38 Average loss: 136.3143\n",
      "====> Test set loss: 138.8820\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 132.220752\n",
      "Train Epoch: 39 [10000/60000 (17%)]\tLoss: 130.355137\n",
      "Train Epoch: 39 [20000/60000 (33%)]\tLoss: 132.902187\n",
      "Train Epoch: 39 [30000/60000 (50%)]\tLoss: 133.980635\n",
      "Train Epoch: 39 [40000/60000 (67%)]\tLoss: 134.470361\n",
      "Train Epoch: 39 [50000/60000 (83%)]\tLoss: 139.505918\n",
      "====> Epoch: 39 Average loss: 136.3449\n",
      "====> Test set loss: 138.6199\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 139.803701\n",
      "Train Epoch: 40 [10000/60000 (17%)]\tLoss: 133.423486\n",
      "Train Epoch: 40 [20000/60000 (33%)]\tLoss: 138.663535\n",
      "Train Epoch: 40 [30000/60000 (50%)]\tLoss: 138.642939\n",
      "Train Epoch: 40 [40000/60000 (67%)]\tLoss: 135.930391\n",
      "Train Epoch: 40 [50000/60000 (83%)]\tLoss: 135.145391\n",
      "====> Epoch: 40 Average loss: 136.1810\n",
      "====> Test set loss: 138.8465\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 138.427656\n",
      "Train Epoch: 41 [10000/60000 (17%)]\tLoss: 138.448145\n",
      "Train Epoch: 41 [20000/60000 (33%)]\tLoss: 129.839922\n",
      "Train Epoch: 41 [30000/60000 (50%)]\tLoss: 137.649141\n",
      "Train Epoch: 41 [40000/60000 (67%)]\tLoss: 137.058662\n",
      "Train Epoch: 41 [50000/60000 (83%)]\tLoss: 125.568633\n",
      "====> Epoch: 41 Average loss: 136.2015\n",
      "====> Test set loss: 137.9827\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 137.503379\n",
      "Train Epoch: 42 [10000/60000 (17%)]\tLoss: 135.850029\n",
      "Train Epoch: 42 [20000/60000 (33%)]\tLoss: 134.440977\n",
      "Train Epoch: 42 [30000/60000 (50%)]\tLoss: 133.566777\n",
      "Train Epoch: 42 [40000/60000 (67%)]\tLoss: 130.000352\n",
      "Train Epoch: 42 [50000/60000 (83%)]\tLoss: 133.839785\n",
      "====> Epoch: 42 Average loss: 136.1276\n",
      "====> Test set loss: 138.2364\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 133.288223\n",
      "Train Epoch: 43 [10000/60000 (17%)]\tLoss: 134.076758\n",
      "Train Epoch: 43 [20000/60000 (33%)]\tLoss: 139.597334\n",
      "Train Epoch: 43 [30000/60000 (50%)]\tLoss: 137.027266\n",
      "Train Epoch: 43 [40000/60000 (67%)]\tLoss: 136.460391\n",
      "Train Epoch: 43 [50000/60000 (83%)]\tLoss: 137.988662\n",
      "====> Epoch: 43 Average loss: 136.0795\n",
      "====> Test set loss: 138.4138\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 131.574951\n",
      "Train Epoch: 44 [10000/60000 (17%)]\tLoss: 132.417979\n",
      "Train Epoch: 44 [20000/60000 (33%)]\tLoss: 136.906660\n",
      "Train Epoch: 44 [30000/60000 (50%)]\tLoss: 129.508740\n",
      "Train Epoch: 44 [40000/60000 (67%)]\tLoss: 136.330762\n",
      "Train Epoch: 44 [50000/60000 (83%)]\tLoss: 135.458125\n",
      "====> Epoch: 44 Average loss: 136.3696\n",
      "====> Test set loss: 138.9408\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 130.984902\n",
      "Train Epoch: 45 [10000/60000 (17%)]\tLoss: 131.222998\n",
      "Train Epoch: 45 [20000/60000 (33%)]\tLoss: 136.941563\n",
      "Train Epoch: 45 [30000/60000 (50%)]\tLoss: 139.924570\n",
      "Train Epoch: 45 [40000/60000 (67%)]\tLoss: 137.640850\n",
      "Train Epoch: 45 [50000/60000 (83%)]\tLoss: 139.087695\n",
      "====> Epoch: 45 Average loss: 136.7199\n",
      "====> Test set loss: 138.4379\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 140.945518\n",
      "Train Epoch: 46 [10000/60000 (17%)]\tLoss: 137.721631\n",
      "Train Epoch: 46 [20000/60000 (33%)]\tLoss: 136.545166\n",
      "Train Epoch: 46 [30000/60000 (50%)]\tLoss: 142.169639\n",
      "Train Epoch: 46 [40000/60000 (67%)]\tLoss: 143.881875\n",
      "Train Epoch: 46 [50000/60000 (83%)]\tLoss: 134.202617\n",
      "====> Epoch: 46 Average loss: 135.9907\n",
      "====> Test set loss: 138.2131\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 134.927637\n",
      "Train Epoch: 47 [10000/60000 (17%)]\tLoss: 137.329824\n",
      "Train Epoch: 47 [20000/60000 (33%)]\tLoss: 131.530693\n",
      "Train Epoch: 47 [30000/60000 (50%)]\tLoss: 134.249043\n",
      "Train Epoch: 47 [40000/60000 (67%)]\tLoss: 133.559912\n",
      "Train Epoch: 47 [50000/60000 (83%)]\tLoss: 136.540576\n",
      "====> Epoch: 47 Average loss: 135.7399\n",
      "====> Test set loss: 138.1610\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 127.374902\n",
      "Train Epoch: 48 [10000/60000 (17%)]\tLoss: 137.477803\n",
      "Train Epoch: 48 [20000/60000 (33%)]\tLoss: 142.031064\n",
      "Train Epoch: 48 [30000/60000 (50%)]\tLoss: 142.622979\n",
      "Train Epoch: 48 [40000/60000 (67%)]\tLoss: 145.218145\n",
      "Train Epoch: 48 [50000/60000 (83%)]\tLoss: 138.399746\n",
      "====> Epoch: 48 Average loss: 136.0417\n",
      "====> Test set loss: 138.5731\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 133.883994\n",
      "Train Epoch: 49 [10000/60000 (17%)]\tLoss: 134.764590\n",
      "Train Epoch: 49 [20000/60000 (33%)]\tLoss: 138.358037\n",
      "Train Epoch: 49 [30000/60000 (50%)]\tLoss: 133.017334\n",
      "Train Epoch: 49 [40000/60000 (67%)]\tLoss: 134.191455\n",
      "Train Epoch: 49 [50000/60000 (83%)]\tLoss: 138.901748\n",
      "====> Epoch: 49 Average loss: 135.9112\n",
      "====> Test set loss: 138.7369\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 137.996914\n",
      "Train Epoch: 50 [10000/60000 (17%)]\tLoss: 133.556992\n",
      "Train Epoch: 50 [20000/60000 (33%)]\tLoss: 129.735928\n",
      "Train Epoch: 50 [30000/60000 (50%)]\tLoss: 137.257158\n",
      "Train Epoch: 50 [40000/60000 (67%)]\tLoss: 135.157119\n",
      "Train Epoch: 50 [50000/60000 (83%)]\tLoss: 141.014219\n",
      "====> Epoch: 50 Average loss: 135.7919\n",
      "====> Test set loss: 137.9652\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 51):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(64, 2).cuda()\n",
    "    sample = vae.decoder(z).cuda()\n",
    "    \n",
    "    save_image(sample.view(64, 1, 28, 28), './sample_' + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
